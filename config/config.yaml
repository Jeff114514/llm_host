# FastAPI vLLM Proxy 配置文件

# vLLM服务配置
vllm_host: localhost
vllm_port: 8002

# sglang 服务配置
sglang_host: localhost
sglang_port: 8003

# FastAPI服务配置
fastapi_host: 0.0.0.0
fastapi_port: 8001

# API Keys文件路径
api_keys_file: config/api_keys.json

# 请求限制配置（null表示不限制）
rate_limit:
  qps: null                    # 每秒请求数限制
  concurrent: null             # 并发连接数限制
  tokens_per_minute: null      # 每分钟token数限制

# 日志级别
log_level: INFO

# 模型路由：模型名 -> 后端类型（vllm/sglang）
# 若为空，则 FastAPI 会尝试从已启动的后端自动发现模型（通过 /v1/models）。
model_backend_mapping: {}

# vLLM 启动与 LoRA 配置
vllm:
  auto_start: true                  # FastAPI 启动时是否自动拉起 vLLM
  launch_mode: python_api            # python_api | cli
  start_cmd_file: config/vllm_start_cmd.txt
  start_cmd: null                    # 可选：直接在此写入启动命令字符串
  log_dir: logs
  log_file: logs/vllm.log
  log_max_size_mb: 100.0
  pid_dir: .pids
  pid_file: .pids/vllm.pid
  python_launcher:
    enabled: true
    conda_env: Jeff-py312
    env_file: null
  extra_env: {}                      # 传递给 vLLM 子进程的额外环境变量
  lora:
    enabled: false               # 启用 LoRA 模式，允许 per-request 切换
    max_lora_rank: 32
    max_loras: 4
    max_cpu_loras: 4                 # 必须 >= max_loras
    preload: []                      # 预加载 LoRA 列表
    # 示例:
    #   - name: sql-lora
    #     path: /path/to/sql-lora
    #     base_model_name: meta-llama/Llama-2-7b
    default_mm_loras: {}             # 多模态输入与 LoRA 的映射
    limit_mm_per_prompt: {}          # 每个模态的 LoRA 限流
    runtime_resolver:
      allow_runtime_updates: true    # 开启动态加载/卸载接口
      plugins:
        - lora_filesystem_resolver
      cache_dir: ./lora_cache

# sglang 启动配置（OpenAI 兼容服务）
sglang:
  auto_start: true                  # FastAPI 启动时是否自动拉起 sglang
  launch_mode: python_api           # python_api | cli
  start_cmd_file: config/sglang_start_cmd.txt
  start_cmd: null                   # 可选：直接在此写入启动命令字符串
  log_dir: logs
  log_file: logs/sglang.log
  log_max_size_mb: 100.0
  pid_dir: .pids
  pid_file: .pids/sglang.pid
  python_launcher:
    enabled: true
    conda_env: Jeff-py312-sgl
    env_file: null
  extra_env:
    CUDA_VISIBLE_DEVICES: "4,5"     # 使用第 5、6 张 GPU 卡（索引从 0 开始，4,5 对应第 5、6 张卡）
